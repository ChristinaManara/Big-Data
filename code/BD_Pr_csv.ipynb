{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tvu-DO_OMgyy"
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init() \n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.types import TimestampType\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# starting SparkSession\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"bg_sql_csv\") \\\n",
    "        .config(\"spark.ui.port\",\"4041\") \\\n",
    "        .config(\"spark.executor.memory\", \"2g\") \\\n",
    "        .config(\"spark.executor.cores\", \"2\") \\\n",
    "        .config(\"spark.task.maxFailures\", \"8\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3hl53iHgCkY"
   },
   "source": [
    "# Read csvs files with inferschema variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "yLvenPk-M897"
   },
   "outputs": [],
   "source": [
    "# Read artist.csv\n",
    "df_artists = spark.read.options(inferSchema='True',delimiter=',') \\\n",
    "  .csv(\"hdfs://master:9000/files/artists.csv\")\n",
    "\n",
    "df_artists = df_artists.withColumnRenamed('_c0','artist_id')\\\n",
    "                       .withColumnRenamed('_c1','artist_name')\n",
    "\n",
    "# Read chart_artist_mapping.csv\n",
    "df_chart_artist_mapping = spark.read.options(inferSchema='True',delimiter=',') \\\n",
    "  .csv(\"hdfs://master:9000/files/chart_artist_mapping.csv\")\n",
    "\n",
    "df_chart_artist_mapping = df_chart_artist_mapping.withColumnRenamed('_c0','song_id')\\\n",
    "                                                 .withColumnRenamed('_c1','artist_id')\n",
    "\n",
    "# Read charts.csv\n",
    "df_charts = spark.read.options(inferSchema='True',delimiter=',') \\\n",
    "  .csv(\"hdfs://master:9000/files/charts.csv\")\n",
    "\n",
    "df_charts = df_charts.withColumnRenamed('_c0','song_id')\\\n",
    "                     .withColumnRenamed('_c1','song_title')\\\n",
    "                     .withColumnRenamed('_c2','rank')\\\n",
    "                     .withColumnRenamed('_c3','date')\\\n",
    "                     .withColumnRenamed('_c4','region_id')\\\n",
    "                     .withColumnRenamed('_c5','chart')\\\n",
    "                     .withColumnRenamed('_c6','chart_traffic')\\\n",
    "                     .withColumnRenamed('_c7','streams')\\\n",
    "                     .withColumn('date',F.col('date')+F.expr('INTERVAL 3 HOURS'))\\\n",
    "                     .withColumn('year',F.year(F.col('date')))\\\n",
    "                     .withColumn('month',F.month(F.col('date')))\\\n",
    "                     .withColumn('day',F.dayofmonth(F.col('date')))\\\n",
    "                     .withColumn('only_date',F.to_date(F.col('date')))\n",
    "\n",
    "# Read regions.csv\n",
    "df_regions = spark.read.options(inferSchema='True',delimiter=',') \\\n",
    "  .csv(\"hdfs://master:9000/files/regions.csv\")\n",
    "\n",
    "df_regions = df_regions.withColumnRenamed('_c0','region_id')\\\n",
    "                       .withColumnRenamed('_c1','region_name')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZsMryhbKhFxg"
   },
   "source": [
    "# Extract parquet files based on dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hIX9ugYHhFdM",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_artists.write.parquet(\"hdfs://master:9000/files/artists.parquet\")\n",
    "# df_chart_artist_mapping.write.parquet(\"hdfs://master:9000/files/chart_artist_mapping.parquet\")\n",
    "# df_charts.write.parquet(\"hdfs://master:9000/files/charts.parquet\")\n",
    "df_regions.write.parquet(\"hdfs://master:9000/files/regions.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lCGCXy8df6TU"
   },
   "source": [
    "# Method SparkSQL with CSV file as input file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HETh3V2gGTmX"
   },
   "source": [
    "## Create Temporary Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gP6poKUAGMDY"
   },
   "outputs": [],
   "source": [
    "df_charts.createOrReplaceTempView(\"charts\")\n",
    "df_regions.createOrReplaceTempView(\"regions\")\n",
    "df_chart_artist_mapping.createOrReplaceTempView(\"chart_artist_mapping\")\n",
    "df_artists.createOrReplaceTempView(\"artists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSODLLzvkb16"
   },
   "source": [
    "## Q1: Ποιο είναι το συνολικό πλήθος των streams που έχουν καταγραφεί για το τραγούδι με τίτλο “Shape of You”, σύμφωνα με τα top200 charts?\n",
    "Ως αποτελέσμα να δωθεί μόνο ένας αριθμός με το πλήθος"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01E-MmJ2kp6K"
   },
   "outputs": [],
   "source": [
    "q1 = spark.sql('''SELECT sum(streams) \n",
    "                  FROM charts \n",
    "                  WHERE song_title = \"Shape of You\" and chart = \"top200\"''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "755h6TAwwKiZ",
    "outputId": "6eb52bf6-4b4e-4409-cd44-54a592478f51"
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "q1.coalesce(1).write.option(\"header\",\"true\").option(\"sep\",\",\").mode(\"overwrite\").csv(\"hdfs://master:9000/outputs/sql_q1_csv.csv\")\n",
    "print(\"Execution Time for q1(csv) is: \",time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GDIzwm14mxwh"
   },
   "source": [
    "## Q2: Για κάθε chart, να βρεθεί το τραγούδι με τον μεγαλύτερο μέσο χρόνο παραμονής (δείτε «Υποδείξεις») στην πρώτη θέση.\n",
    "Ως αποτέλεσμα, αναμένονται δύο γραμμές, μία για κάθε chart στην μορφή:\n",
    "όνομα_chart, όνομα_τραγουδιού, μέσος_χρόνος_παραμονής_θέση#1\n",
    "Αναμενόμενο αποτέλεσμα στο viral50 chart viral50,Calma - Remix,24.985507"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GCG02dvHuDiV"
   },
   "outputs": [],
   "source": [
    "q2 = spark.sql('''select chart, song_title, avg_cnt from (select chart, song_title, t.avg_cnt, max(t.avg_cnt) over (partition by t.chart) as max_r\n",
    "                    from (select chart,song_title,count(*)/69 as avg_cnt\n",
    "                          from charts\n",
    "                          where rank = 1\n",
    "                          group by chart, song_title)t)t1\n",
    "                    where avg_cnt = max_r\n",
    "                    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76POQmJyJjFD",
    "outputId": "c441b9e5-5bf3-4984-a552-91bbd98b84be"
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "q2.coalesce(1).write.option(\"header\",\"true\").option(\"sep\",\",\").mode(\"overwrite\").csv(\"hdfs://master:9000/outputs/sql_q2_csv.csv\")\n",
    "print(\"Execution Time for q2(csv) is: \",time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FparfkG83qRs"
   },
   "source": [
    "## Q3: Από τα top200 charts, να βρεθεί για κάθε μήνα της κάθε χρονιάς, το μέσο ημερήσιο πλήθος streams του τραγουδιού που βρίσκεται στην θέση 1 (δείτε «Υποδείξεις»), ταξινομημένα ως προς την χρονιά και τον μήνα."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bczNLPg545ci"
   },
   "outputs": [],
   "source": [
    "q3 = spark.sql('''SELECT year, month, avg_daily_sum \n",
    "                  FROM (SELECT year, month, sum(streams)/count(distinct day) as avg_daily_sum\n",
    "                  FROM charts \n",
    "                  WHERE rank = 1 and chart = \"top200\"\n",
    "                  GROUP BY year, month\n",
    "                  ORDER BY year, month asc) t\n",
    "                  ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TGkLKDVwW0nD",
    "outputId": "addd1954-74fd-4602-f745-c8779f0c50f6"
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "q3.coalesce(1).write.option(\"header\",\"true\").option(\"sep\",\",\").mode(\"overwrite\").csv(\"hdfs://master:9000/outputs/sql_q3_csv.csv\")\n",
    "print(\"Execution Time for q3(csv) is: \",time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-RC3ufYOJ2_F"
   },
   "source": [
    "## Q4: Από τα viral50 charts, βρείτε για κάθε χώρα το (ή τα σε περίπτωση ισοψηφίας) τραγούδια με το μεγαλύτερο πλήθος παραμονής στο charts. Ταξινομείστε τα αποτελέσματα σας ως προς το όνομα της χώρας και το όνομα του τραγουδιού. Ως αποτέλεσμα δώστε μία γραμμή για κάθε τραγούδι κάθε χώρας στην μορφή :\n",
    "χώρα, id_τραγουδιού, όνομα_τραγουδιού, πλήθος_παραμονής_στο_viral50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "poEDnqh5_TB6"
   },
   "outputs": [],
   "source": [
    "q4 = spark.sql('''select regions.region_name, t2.song_id, t2.song_title, t2.cnt\n",
    "                  from regions\n",
    "                  inner join (SELECT region_id, song_id, song_title,cnt FROM (SELECT region_id, song_id,song_title, t.cnt,max(t.cnt) over (partition by t.region_id) as max_r FROM \n",
    "                  (SELECT region_id, song_id,song_title, count(*) as cnt\n",
    "                  FROM charts\n",
    "                  WHERE chart = \"viral50\"\n",
    "                  GROUP BY region_id, song_id, song_title) t\n",
    "                  order by t.cnt desc) t1\n",
    "                  where t1.cnt = t1.max_r) t2\n",
    "                  on regions.region_id = t2.region_id\n",
    "                  order By regions.region_name,  t2.song_title''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IEO79TdUXI7u",
    "outputId": "a6072934-e470-4174-9121-df7d14c2a143"
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "q4.coalesce(1).write.option(\"header\",\"true\").option(\"sep\",\",\").mode(\"overwrite\").csv(\"hdfs://master:9000/outputs/sql_q4_csv.csv\")\n",
    "print(\"Execution Time for q4(csv) is: \",time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CALYZJFUh-3c"
   },
   "source": [
    "## Q5:Σύμφωνα με τα top200, βρείτε σε κάθε χρονιά τον καλλιτέχνη με το μεγαλύτερο μέσο πλήθος streams. Ταξινομείστε ως προς τη χρονιά.\n",
    "Ως αποτελέσμα, δώστε για κάθε χρονιά μία γραμμή στην εξής μορφή\n",
    "χρονιά, όνομα_καλλιτέχνη, μέσο_πλήθος_streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SqzF_3LoUdfe"
   },
   "outputs": [],
   "source": [
    "q5 = spark.sql('''select year, artist_name, total_streams as avg_streams \n",
    "                  from(select year, artist_name, total_streams, max(total_streams) over (partition by year) as max_streams\n",
    "                       from (select year, artist_name, sum(streams)/69 as total_streams \n",
    "                             from(select * \n",
    "                                  from (select * \n",
    "                                        from (select * \n",
    "                                              from charts\n",
    "                                              where chart = \"top200\") t\n",
    "                                              left join chart_artist_mapping\n",
    "                                              on t.song_id = chart_artist_mapping.song_id) t1\n",
    "                                        inner join artists\n",
    "                                        on t1.artist_id = artists.artist_id ) t2 \n",
    "                                  group by year, artist_name) t3) t4   \n",
    "                  where total_streams = max_streams\n",
    "                  order by year\n",
    "                  ''')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rM6QIloHgwpX",
    "outputId": "a0cc3458-191e-4210-a2d0-5146a1437b69"
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "q5.coalesce(1).write.option(\"header\",\"true\").option(\"sep\",\",\").mode(\"overwrite\").csv(\"hdfs://master:9000/outputs/sql_q5_csv.csv\")\n",
    "print(\"Execution Time for q5(csv) is: \",time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ru6tauRhjM3C"
   },
   "source": [
    "## Q6: Για την Ελλάδα, βρείτε για κάθε χρονιά και chart τον καλλιτέχνη (ή τους καλλιτέχνες) που έχει (έχουν) παραμείνει διαδοχικές ημέρες περισσότερες φορές στο #1 κάποιο από τα τραγούδια του. Ταξινομείστε ως προς το chart και τη χρονιά.\n",
    "Ως αποτελέσμα δώστε μία γραμμή για κάθε καλλιτέχνη κάθε χρονιάς στη μορφή: όνομα_chart, χρονιά, όνομα καλλιτέχνη, ημέρες_διαδοχικής_παραμονής_#1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dOKdRwbtTomC"
   },
   "outputs": [],
   "source": [
    "q6 = spark.sql('''With table_1 as(select chart, year, song_id, max_streak\n",
    "                     from (select chart, year, song_id, sum(cnt) as streak, max(sum(cnt)) over (partition by chart,year) as max_streak\n",
    "                            from (select chart, year, song_id ,date_group, count(*) as cnt,min(date),max(date) \n",
    "                                  from (select chart, year, song_id, date, date_add(date, - rank() over (partition by chart, year, song_id order by date)) as date_group\n",
    "                                        from (select chart, year, song_id, only_date as date\n",
    "                                              from charts\n",
    "                                              where region_id = 23 and chart_traffic = \"SAME_POSITION\" and rank = 1) in_t ) t\n",
    "                            group by chart, year, song_id,date_group) t1\n",
    "                            group by chart, year, song_id) t3\n",
    "                     where streak = max_streak),\n",
    "                     table_2 as (select song_id, artists.artist_name \n",
    "                                from (select charts.song_id as song_id, chart_artist_mapping.artist_id as artist_id \n",
    "                                      from charts\n",
    "                                      left join chart_artist_mapping\n",
    "                                      on charts.song_id = chart_artist_mapping.song_id) t1\n",
    "                                inner join artists\n",
    "                                on t1.artist_id = artists.artist_id) \n",
    "                      select Distinct chart, year, artist_name, max_streak\n",
    "                      from table_1\n",
    "                      inner join table_2 \n",
    "                      on table_1.song_id = table_2.song_id\n",
    "                      order by chart desc, year \n",
    "                     ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G7M3q-IVTF_G",
    "outputId": "36ee86de-507f-484d-ca7f-63fb66d008f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time for q6(csv) is:  61.98225927352905\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "q6.coalesce(1).write.option(\"header\",\"true\").option(\"sep\",\",\").mode(\"overwrite\").csv(\"hdfs://master:9000/outputs/sql_q6_csv.csv\")\n",
    "print(\"Execution Time for q6(csv) is: \",time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Big_Data_Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
